# -*- coding: utf-8 -*-
"""guardrail.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dUd-iKfCXFAFYq64I5x3gFbJIpJvD_5V
"""

import boto3
import json
import datetime
from botocore.exceptions import ClientError

bedrock_client = boto3.client('bedrock-runtime')
guardrail_client = boto3.client('your-guardrail-service')  # Replace with the actual client for your guardrail service

def check_with_guardrail(response_text, guardrail_identifier, version):
    """
    Check the response with an external guardrail service.
    Args:
        response_text (str): The text generated by the model.
        guardrail_identifier (str): The identifier for the guardrail.
        version (str): The version of the guardrail to use.
    Returns:
        bool: True if the response is blocked, False otherwise.
    """
    try:
        response = guardrail_client.check_text(
            Text=response_text,
            GuardrailIdentifier=guardrail_identifier,
            Version=version
        )
        return response.get("Blocked", False)
    except ClientError as e:
        # Log error and decide whether to fail open or fail closed
        print(f"Guardrail check failed: {e.response['Error']['Message']}")
        return True  # Default to blocking if the guardrail service fails

def lambda_handler(event, context):
    subject = "Meeting Update"
    email_body = "Please confirm your availability for the team meeting tomorrow."
    prompt = f"Generate a professional response for the following:\nSubject: {subject}\nEmail Body: {email_body}"

    native_request = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 512,
        "temperature": 0.5,
        "messages": [
            {
                "role": "user",
                "content": [{"type": "text", "text": prompt}],
            }
        ],
    }

    request = json.dumps(native_request)

    try:
        response = bedrock_client.invoke_model(
            modelId="anthropic.claude-3-5-sonnet-20240620-v1:0",
            body=request,
            contentType="application/json"
        )

        response_body = response["body"].read().decode("utf-8")
        model_response = json.loads(response_body)

        response_text = ""

        if "content" in model_response and len(model_response["content"]) > 0:
            response_text = model_response["content"][0].get("text", "No response generated")

            # Use the external guardrail service
            guardrail_identifier = "your-guardrail-identifier"  # Replace with actual identifier
            guardrail_version = "v1.0"  # Replace with actual version
            if check_with_guardrail(response_text, guardrail_identifier, guardrail_version):
                response_text = "Sorry the model cannot generate the response for this request."

        today_date = datetime.date.today().isoformat()
        output_data = {
            "Date": today_date,
            "MessageID": context.aws_request_id if context else "test-message-id",
            "Body": response_text,
        }

        return {
            "statusCode": 200,
            "body": json.dumps(output_data)
        }

    except ClientError as e:
        error_message = f"ClientError: {e.response['Error']['Message']}"
        return {
            "statusCode": 500,
            "body": json.dumps({"error": error_message})
        }
    except Exception as e:
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }